{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7052855,"sourceType":"datasetVersion","datasetId":4059258},{"sourceId":7053360,"sourceType":"datasetVersion","datasetId":4059580},{"sourceId":8149185,"sourceType":"datasetVersion","datasetId":4819438},{"sourceId":8149361,"sourceType":"datasetVersion","datasetId":4819558},{"sourceId":8149479,"sourceType":"datasetVersion","datasetId":4819658},{"sourceId":8389437,"sourceType":"datasetVersion","datasetId":4989967},{"sourceId":8413123,"sourceType":"datasetVersion","datasetId":5007443},{"sourceId":8413474,"sourceType":"datasetVersion","datasetId":5007723},{"sourceId":8413478,"sourceType":"datasetVersion","datasetId":5007726},{"sourceId":8433673,"sourceType":"datasetVersion","datasetId":5022970},{"sourceId":8433923,"sourceType":"datasetVersion","datasetId":5023145},{"sourceId":8437661,"sourceType":"datasetVersion","datasetId":5025900},{"sourceId":8437901,"sourceType":"datasetVersion","datasetId":5026097}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Note: If you want to work on this project . please contact the owner first.\n# Do not make any changes without contacting with owner.Thanks!\n!pip -qqq install git+https://github.com/openai/whisper.git #cloning whisper model\n!pip -qqq install pytube\n!pip install pydub\n\n!wget https://raw.githubusercontent.com/justinjohn0306/Wav2Lip/main/requirements.txt\n\n\n!pip install ffmpeg-python mediapipe==0.8.11\n!pip install moviepy\n# !pip install update googletrans\n\n!pip uninstall -y pydantic\n!pip uninstall -y typing-extensions\n!pip install pydantic==2.4.2\n!pip install typing-extensions==4.8.0\n# !pip install googletrans==4.0.0-rc1\n\n#This is for 11lab dependencies\n# !pip uninstall -y pydantic\n# !pip uninstall -y typing-extensions\n# !pip install pydantic==2.4.2\n# !pip install typing-extensions==4.8.0\n\n!pip install -U deep-translator\n\n!pip install elevenlabs\n\n# Download the requirements.txt of wav2lip\n!git clone https://github.com/justinjohn0306/Wav2Lip\n\n%cd Wav2Lip\n\n#download the pretrained model\n!wget 'https://github.com/justinjohn0306/Wav2Lip/releases/download/models/wav2lip.pth' -O 'checkpoints/wav2lip.pth'\n!wget 'https://github.com/justinjohn0306/Wav2Lip/releases/download/models/wav2lip_gan.pth' -O 'checkpoints/wav2lip_gan.pth'\n!wget 'https://github.com/justinjohn0306/Wav2Lip/releases/download/models/resnet50.pth' -O 'checkpoints/resnet50.pth'\n!wget 'https://github.com/justinjohn0306/Wav2Lip/releases/download/models/mobilenet.pth' -O 'checkpoints/mobilenet.pth'\na = !pip install https://raw.githubusercontent.com/AwaleSajil/ghc/master/ghc-1.0-py3-none-any.whl\n!pip install git+https://github.com/elliottzheng/batch-face.git@master\n\n!pip install ffmpeg-python mediapipe==0.8.11","metadata":{"id":"3WJMTS6gkU1L","execution":{"iopub.status.busy":"2024-06-13T04:55:34.323218Z","iopub.execute_input":"2024-06-13T04:55:34.323878Z","iopub.status.idle":"2024-06-13T04:58:48.185403Z","shell.execute_reply.started":"2024-06-13T04:55:34.323850Z","shell.execute_reply":"2024-06-13T04:58:48.184147Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (0.25.1)\n--2024-06-13 04:56:33--  https://raw.githubusercontent.com/justinjohn0306/Wav2Lip/main/requirements.txt\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 404 Not Found\n2024-06-13 04:56:33 ERROR 404: Not Found.\n\nCollecting ffmpeg-python\n  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n\u001b[31mERROR: Could not find a version that satisfies the requirement mediapipe==0.8.11 (from versions: 0.9.1.0, 0.9.2.1, 0.9.3.0, 0.10.0, 0.10.1, 0.10.2, 0.10.3, 0.10.5, 0.10.7, 0.10.8, 0.10.9, 0.10.10, 0.10.11, 0.10.13, 0.10.14)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for mediapipe==0.8.11\u001b[0m\u001b[31m\n\u001b[0mCollecting moviepy\n  Downloading moviepy-1.0.3.tar.gz (388 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.3/388.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting decorator<5.0,>=4.0.2 (from moviepy)\n  Downloading decorator-4.4.2-py2.py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: tqdm<5.0,>=4.11.2 in /opt/conda/lib/python3.10/site-packages (from moviepy) (4.66.1)\nRequirement already satisfied: requests<3.0,>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from moviepy) (2.31.0)\nCollecting proglog<=1.0.0 (from moviepy)\n  Downloading proglog-0.1.10-py3-none-any.whl.metadata (639 bytes)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from moviepy) (1.24.4)\nRequirement already satisfied: imageio<3.0,>=2.5 in /opt/conda/lib/python3.10/site-packages (from moviepy) (2.33.1)\nCollecting imageio_ffmpeg>=0.2.0 (from moviepy)\n  Downloading imageio_ffmpeg-0.5.1-py3-none-manylinux2010_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: pillow>=8.3.2 in /opt/conda/lib/python3.10/site-packages (from imageio<3.0,>=2.5->moviepy) (9.5.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from imageio_ffmpeg>=0.2.0->moviepy) (69.0.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (2023.11.17)\nDownloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\nDownloading imageio_ffmpeg-0.5.1-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\nBuilding wheels for collected packages: moviepy\n  Building wheel for moviepy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for moviepy: filename=moviepy-1.0.3-py3-none-any.whl size=110720 sha256=df140202798cda7f47d9a1ced3f2e8dc014bfe8a36f0c4a4bab0406ac2476813\n  Stored in directory: /root/.cache/pip/wheels/96/32/2d/e10123bd88fbfc02fed53cc18c80a171d3c87479ed845fa7c1\nSuccessfully built moviepy\nInstalling collected packages: proglog, imageio_ffmpeg, decorator, moviepy\n  Attempting uninstall: decorator\n    Found existing installation: decorator 5.1.1\n    Uninstalling decorator-5.1.1:\n      Successfully uninstalled decorator-5.1.1\nSuccessfully installed decorator-4.4.2 imageio_ffmpeg-0.5.1 moviepy-1.0.3 proglog-0.1.10\nFound existing installation: pydantic 2.5.3\nUninstalling pydantic-2.5.3:\n  Successfully uninstalled pydantic-2.5.3\nFound existing installation: typing_extensions 4.9.0\nUninstalling typing_extensions-4.9.0:\n  Successfully uninstalled typing_extensions-4.9.0\nCollecting pydantic==2.4.2\n  Downloading pydantic-2.4.2-py3-none-any.whl.metadata (158 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.6/158.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic==2.4.2) (0.6.0)\nCollecting pydantic-core==2.10.1 (from pydantic==2.4.2)\n  Downloading pydantic_core-2.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\nCollecting typing-extensions>=4.6.1 (from pydantic==2.4.2)\n  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\nDownloading pydantic-2.4.2-py3-none-any.whl (395 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.8/395.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading pydantic_core-2.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\nInstalling collected packages: typing-extensions, pydantic-core, pydantic\n  Attempting uninstall: pydantic-core\n    Found existing installation: pydantic_core 2.14.6\n    Uninstalling pydantic_core-2.14.6:\n      Successfully uninstalled pydantic_core-2.14.6\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.3.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\ncuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\ndask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\njupyterlab 4.0.11 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.2 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\ntensorflowjs 4.16.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed pydantic-2.4.2 pydantic-core-2.10.1 typing-extensions-4.12.2\nCollecting typing-extensions==4.8.0\n  Downloading typing_extensions-4.8.0-py3-none-any.whl.metadata (3.0 kB)\nDownloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\nInstalling collected packages: typing-extensions\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.12.2\n    Uninstalling typing_extensions-4.12.2:\n      Successfully uninstalled typing_extensions-4.12.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.3.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\ncuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\ndask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\njupyterlab 4.0.11 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.2 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\ntensorflowjs 4.16.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed typing-extensions-4.8.0\nCollecting deep-translator\n  Downloading deep_translator-1.11.4-py3-none-any.whl.metadata (30 kB)\nRequirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /opt/conda/lib/python3.10/site-packages (from deep-translator) (4.12.2)\nRequirement already satisfied: requests<3.0.0,>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from deep-translator) (2.31.0)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2023.11.17)\nDownloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m786.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: deep-translator\nSuccessfully installed deep-translator-1.11.4\nCollecting elevenlabs\n  Downloading elevenlabs-1.3.0-py3-none-any.whl.metadata (9.9 kB)\nCollecting httpx>=0.21.2 (from elevenlabs)\n  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\nRequirement already satisfied: pydantic>=1.9.2 in /opt/conda/lib/python3.10/site-packages (from elevenlabs) (2.4.2)\nRequirement already satisfied: requests>=2.20 in /opt/conda/lib/python3.10/site-packages (from elevenlabs) (2.31.0)\nRequirement already satisfied: typing_extensions>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from elevenlabs) (4.8.0)\nRequirement already satisfied: websockets>=11.0 in /opt/conda/lib/python3.10/site-packages (from elevenlabs) (12.0)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.21.2->elevenlabs) (4.2.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.21.2->elevenlabs) (2023.11.17)\nCollecting httpcore==1.* (from httpx>=0.21.2->elevenlabs)\n  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx>=0.21.2->elevenlabs) (3.6)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.21.2->elevenlabs) (1.3.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.21.2->elevenlabs) (0.14.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.9.2->elevenlabs) (0.6.0)\nRequirement already satisfied: pydantic-core==2.10.1 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.9.2->elevenlabs) (2.10.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->elevenlabs) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->elevenlabs) (1.26.18)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx>=0.21.2->elevenlabs) (1.2.0)\nDownloading elevenlabs-1.3.0-py3-none-any.whl (127 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.8/127.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: httpcore, httpx, elevenlabs\nSuccessfully installed elevenlabs-1.3.0 httpcore-1.0.5 httpx-0.27.0\nCloning into 'Wav2Lip'...\nremote: Enumerating objects: 513, done.\u001b[K\nremote: Counting objects: 100% (8/8), done.\u001b[K\nremote: Compressing objects: 100% (5/5), done.\u001b[K\nremote: Total 513 (delta 3), reused 7 (delta 3), pack-reused 505\u001b[K\nReceiving objects: 100% (513/513), 29.76 MiB | 36.19 MiB/s, done.\nResolving deltas: 100% (263/263), done.\n/kaggle/working/Wav2Lip\n--2024-06-13 04:58:06--  https://github.com/justinjohn0306/Wav2Lip/releases/download/models/wav2lip.pth\nResolving github.com (github.com)... 140.82.114.4\nConnecting to github.com (github.com)|140.82.114.4|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://objects.githubusercontent.com/github-production-release-asset-2e65be/615543729/e18ec62e-10ae-4c65-9862-1c7a0fafe228?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240613%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240613T045807Z&X-Amz-Expires=300&X-Amz-Signature=03526e367c0173dba0ae3467247ed6320127076c147ac98b12f43b3ffa5fc752&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=615543729&response-content-disposition=attachment%3B%20filename%3Dwav2lip.pth&response-content-type=application%2Foctet-stream [following]\n--2024-06-13 04:58:07--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/615543729/e18ec62e-10ae-4c65-9862-1c7a0fafe228?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240613%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240613T045807Z&X-Amz-Expires=300&X-Amz-Signature=03526e367c0173dba0ae3467247ed6320127076c147ac98b12f43b3ffa5fc752&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=615543729&response-content-disposition=attachment%3B%20filename%3Dwav2lip.pth&response-content-type=application%2Foctet-stream\nResolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\nConnecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 435807851 (416M) [application/octet-stream]\nSaving to: 'checkpoints/wav2lip.pth'\n\ncheckpoints/wav2lip 100%[===================>] 415.62M   212MB/s    in 2.0s    \n\n2024-06-13 04:58:09 (212 MB/s) - 'checkpoints/wav2lip.pth' saved [435807851/435807851]\n\n--2024-06-13 04:58:10--  https://github.com/justinjohn0306/Wav2Lip/releases/download/models/wav2lip_gan.pth\nResolving github.com (github.com)... 140.82.112.3\nConnecting to github.com (github.com)|140.82.112.3|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://objects.githubusercontent.com/github-production-release-asset-2e65be/615543729/76281b9f-48b8-4cbf-9a05-edf61d847109?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240613%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240613T045810Z&X-Amz-Expires=300&X-Amz-Signature=5235958828517c52ac439eb3e248fcbbfee4685f9064ea5b6e5499c19aa334dc&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=615543729&response-content-disposition=attachment%3B%20filename%3Dwav2lip_gan.pth&response-content-type=application%2Foctet-stream [following]\n--2024-06-13 04:58:10--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/615543729/76281b9f-48b8-4cbf-9a05-edf61d847109?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240613%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240613T045810Z&X-Amz-Expires=300&X-Amz-Signature=5235958828517c52ac439eb3e248fcbbfee4685f9064ea5b6e5499c19aa334dc&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=615543729&response-content-disposition=attachment%3B%20filename%3Dwav2lip_gan.pth&response-content-type=application%2Foctet-stream\nResolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\nConnecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 435801865 (416M) [application/octet-stream]\nSaving to: 'checkpoints/wav2lip_gan.pth'\n\ncheckpoints/wav2lip 100%[===================>] 415.61M   209MB/s    in 2.0s    \n\n2024-06-13 04:58:12 (209 MB/s) - 'checkpoints/wav2lip_gan.pth' saved [435801865/435801865]\n\n--2024-06-13 04:58:13--  https://github.com/justinjohn0306/Wav2Lip/releases/download/models/resnet50.pth\nResolving github.com (github.com)... 140.82.114.3\nConnecting to github.com (github.com)|140.82.114.3|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://objects.githubusercontent.com/github-production-release-asset-2e65be/615543729/e6d9110e-3336-450e-b785-bedbfc3b1708?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240613%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240613T045813Z&X-Amz-Expires=300&X-Amz-Signature=34ec49b6a7976c8955f9debf0ab8837cc1ac88953057428980c91b5d7688f254&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=615543729&response-content-disposition=attachment%3B%20filename%3Dresnet50.pth&response-content-type=application%2Foctet-stream [following]\n--2024-06-13 04:58:13--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/615543729/e6d9110e-3336-450e-b785-bedbfc3b1708?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240613%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240613T045813Z&X-Amz-Expires=300&X-Amz-Signature=34ec49b6a7976c8955f9debf0ab8837cc1ac88953057428980c91b5d7688f254&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=615543729&response-content-disposition=attachment%3B%20filename%3Dresnet50.pth&response-content-type=application%2Foctet-stream\nResolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\nConnecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 109497761 (104M) [application/octet-stream]\nSaving to: 'checkpoints/resnet50.pth'\n\ncheckpoints/resnet5 100%[===================>] 104.42M   245MB/s    in 0.4s    \n\n2024-06-13 04:58:14 (245 MB/s) - 'checkpoints/resnet50.pth' saved [109497761/109497761]\n\n--2024-06-13 04:58:15--  https://github.com/justinjohn0306/Wav2Lip/releases/download/models/mobilenet.pth\nResolving github.com (github.com)... 140.82.113.3\nConnecting to github.com (github.com)|140.82.113.3|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://objects.githubusercontent.com/github-production-release-asset-2e65be/615543729/0f1702ef-4998-4acd-abc8-b80c52e838b9?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240613%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240613T045815Z&X-Amz-Expires=300&X-Amz-Signature=d0b12e800fac44cb7443b9fca9cfd286dd66053ddecfdf5ba023915b32b1651e&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=615543729&response-content-disposition=attachment%3B%20filename%3Dmobilenet.pth&response-content-type=application%2Foctet-stream [following]\n--2024-06-13 04:58:15--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/615543729/0f1702ef-4998-4acd-abc8-b80c52e838b9?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240613%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240613T045815Z&X-Amz-Expires=300&X-Amz-Signature=d0b12e800fac44cb7443b9fca9cfd286dd66053ddecfdf5ba023915b32b1651e&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=615543729&response-content-disposition=attachment%3B%20filename%3Dmobilenet.pth&response-content-type=application%2Foctet-stream\nResolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\nConnecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1789735 (1.7M) [application/octet-stream]\nSaving to: 'checkpoints/mobilenet.pth'\n\ncheckpoints/mobilen 100%[===================>]   1.71M  --.-KB/s    in 0.07s   \n\n2024-06-13 04:58:15 (25.1 MB/s) - 'checkpoints/mobilenet.pth' saved [1789735/1789735]\n\nCollecting git+https://github.com/elliottzheng/batch-face.git@master\n  Cloning https://github.com/elliottzheng/batch-face.git (to revision master) to /tmp/pip-req-build-rupd9p4a\n  Running command git clone --filter=blob:none --quiet https://github.com/elliottzheng/batch-face.git /tmp/pip-req-build-rupd9p4a\n  Resolved https://github.com/elliottzheng/batch-face.git to commit 376a9d4355686d904722ed2770502f92c861109a\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from batch-face==1.4.0) (1.24.4)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from batch-face==1.4.0) (2.1.2)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from batch-face==1.4.0) (0.16.2)\nRequirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (from batch-face==1.4.0) (4.9.0.80)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->batch-face==1.4.0) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->batch-face==1.4.0) (4.8.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->batch-face==1.4.0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->batch-face==1.4.0) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->batch-face==1.4.0) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->batch-face==1.4.0) (2023.12.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision->batch-face==1.4.0) (2.31.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->batch-face==1.4.0) (9.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->batch-face==1.4.0) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->batch-face==1.4.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->batch-face==1.4.0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->batch-face==1.4.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->batch-face==1.4.0) (2023.11.17)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->batch-face==1.4.0) (1.3.0)\nBuilding wheels for collected packages: batch-face\n  Building wheel for batch-face (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for batch-face: filename=batch_face-1.4.0-py3-none-any.whl size=30619287 sha256=bf0b0ca75569418c6cf36fab572f467e0ee1199d042140eb06d022ee6ecca42e\n  Stored in directory: /tmp/pip-ephem-wheel-cache-6jez_ql8/wheels/f0/92/95/9242b4d03b2fb9ee9942e0dff04c5eef8185c017bdf252a7ad\nSuccessfully built batch-face\nInstalling collected packages: batch-face\nSuccessfully installed batch-face-1.4.0\nCollecting ffmpeg-python\n  Using cached ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n\u001b[31mERROR: Could not find a version that satisfies the requirement mediapipe==0.8.11 (from versions: 0.9.1.0, 0.9.2.1, 0.9.3.0, 0.10.0, 0.10.1, 0.10.2, 0.10.3, 0.10.5, 0.10.7, 0.10.8, 0.10.9, 0.10.10, 0.10.11, 0.10.13, 0.10.14)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for mediapipe==0.8.11\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport os\nimport librosa\nimport whisper\nfrom pydub import AudioSegment\n# !pip install moviepy\nfrom moviepy.editor import VideoFileClip\n# from googletrans import Translator\nfrom base64 import b64decode\nimport numpy as np\nfrom scipy.io.wavfile import read as wav_read\nimport io\n# import ffmpeg\nimport soundfile as sf\nfrom IPython.display import Audio\nfrom IPython.core.display import display\nimport shutil\n# from googletrans import Translator\nfrom IPython.display import clear_output\nfrom base64 import b64encode\n#!pip install -U deep-translator\nimport moviepy.editor as mp\nfrom elevenlabs.client import ElevenLabs\nfrom elevenlabs import play, save\nfrom base64 import b64encode\nfrom deep_translator import GoogleTranslator\n\n#from pytube import YouTube","metadata":{"id":"7Y4m7Sac6WGK","execution":{"iopub.status.busy":"2024-06-13T04:58:48.187915Z","iopub.execute_input":"2024-06-13T04:58:48.188304Z","iopub.status.idle":"2024-06-13T04:58:53.318191Z","shell.execute_reply.started":"2024-06-13T04:58:48.188265Z","shell.execute_reply":"2024-06-13T04:58:53.317388Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"\n# Set the device\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Load the model\nwhisper_model = whisper.load_model(\"large\", device=device)","metadata":{"id":"q0Yy4ho0kf56","outputId":"1ef31d7c-a4a2-42ec-8cb3-db5fb60dd473","execution":{"iopub.status.busy":"2024-06-13T04:59:53.780703Z","iopub.execute_input":"2024-06-13T04:59:53.780966Z","iopub.status.idle":"2024-06-13T05:00:23.002939Z","shell.execute_reply.started":"2024-06-13T04:59:53.780943Z","shell.execute_reply":"2024-06-13T05:00:23.001535Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":4,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load the model\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m whisper_model \u001b[38;5;241m=\u001b[39m \u001b[43mwhisper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlarge\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/whisper/__init__.py:156\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, device, download_root, in_memory)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m alignment_heads \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m     model\u001b[38;5;241m.\u001b[39mset_alignment_heads(alignment_heads)\n\u001b[0;32m--> 156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","    \u001b[0;31m[... skipping similar frames: Module._apply at line 810 (2 times)]\u001b[0m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:833\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 833\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1158\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 19.06 MiB is free. Process 3114 has 14.73 GiB memory in use. Of the allocated memory 14.07 GiB is allocated by PyTorch, and 551.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 19.06 MiB is free. Process 3114 has 14.73 GiB memory in use. Of the allocated memory 14.07 GiB is allocated by PyTorch, and 551.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","output_type":"error"}]},{"cell_type":"code","source":"# import os\n# from moviepy.editor import VideoFileClip\n\ndef video_to_audio(video_path, destination, final_filename):\n    # Check if the file path is valid\n    if not os.path.isfile(video_path):\n        raise ValueError(f\"The provided path '{video_path}' is not a valid file.\")\n\n    # Load the video file\n    video_clip = VideoFileClip(video_path)\n\n    # Extract audio from the video\n    audio_clip = video_clip.audio\n\n    # Set the destination path for the audio file\n    path_audio = os.path.join(destination, final_filename + \".wav\")\n\n    # Write the audio file\n    audio_clip.write_audiofile(path_audio)\n\n    return path_audio\nname=\"Biden\"\n# Example usage\nvideo_path = \"/kaggle/input/ukrain-war/ukrain.mp4\"\ndestination = \"/kaggle/working/\"\nfinal_filename = \"Ukr\"\npath_audio = video_to_audio(video_path, destination, final_filename)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-17T08:09:46.335294Z","iopub.execute_input":"2024-05-17T08:09:46.335966Z","iopub.status.idle":"2024-05-17T08:09:46.672282Z","shell.execute_reply.started":"2024-05-17T08:09:46.335931Z","shell.execute_reply":"2024-05-17T08:09:46.671312Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"MoviePy - Writing audio in /kaggle/working/Ukr.wav\n","output_type":"stream"},{"name":"stderr","text":"                                                                    ","output_type":"stream"},{"name":"stdout","text":"MoviePy - Done.\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}]},{"cell_type":"code","source":"path=destination + final_filename\ntype=\".wav\"\naudio_file = path+type\n#audio_file = \"/content/drive/MyDrive/imran2.mp3\"\nresult = whisper_model.transcribe(audio_file)\ntranscribe_text = result['text']\nprint(transcribe_text)\n","metadata":{"id":"_5lB0-AKkrZG","outputId":"5fc6e67d-d172-4c0b-bc6f-5ace61da88da","execution":{"iopub.status.busy":"2024-05-17T08:10:09.880335Z","iopub.execute_input":"2024-05-17T08:10:09.882042Z","iopub.status.idle":"2024-05-17T08:10:16.408586Z","shell.execute_reply.started":"2024-05-17T08:10:09.882013Z","shell.execute_reply":"2024-05-17T08:10:16.407624Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":" First, though, here on Verified Live, we have a BBC investigation which suggests at least 25,000 Russian soldiers have been killed in Ukraine, four times higher than the figure acknowledged by Moscow. The research also suggests many of the casualties are now older fighters with little or no training. Significant numbers have also been recruited from prisons. Here's our correspondent Olga Evshina with this special report. Oksinenko, Maxim Anatolievich. These are...\n","output_type":"stream"}]},{"cell_type":"code","source":"#!pip uninstall -y googletrans==4.0.0-rc1\n# !pip install update googletrans\n# from googletrans import Translator","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text=\"The hand of dear Suleimani has lifted us, and his dear hand was seen next to his coffin in films and axes. His revenge is to raise America's foot from this region and take it away. If America's foot is raised from this region and the hand of its aggression is cut off forever, this is the real revenge and the final answer of the region's nations to America.\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install -U deep-translator\n\n# !poetry add deep-translator   # for poetry usage\n\n# from deep_translator import GoogleTranslator\n\n# Use any translator you like, in this example GoogleTranslator\nfrom deep_translator import GoogleTranslator\n\n# Use any translator you like, in this example GoogleTranslator\ntext = GoogleTranslator(source='auto', target='ur')\ntranslated_text = text.translate(transcribe_text)\nprint(translated_text)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T08:10:20.357815Z","iopub.execute_input":"2024-05-17T08:10:20.358189Z","iopub.status.idle":"2024-05-17T08:10:20.491755Z","shell.execute_reply.started":"2024-05-17T08:10:20.358159Z","shell.execute_reply":"2024-05-17T08:10:20.490834Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"پہلے، اگرچہ، یہاں تصدیق شدہ لائیو پر، ہمارے پاس بی بی سی کی ایک تفتیش ہے جس سے پتہ چلتا ہے کہ یوکرین میں کم از کم 25,000 روسی فوجی مارے گئے ہیں، جو ماسکو کی طرف سے تسلیم کیے گئے اعداد و شمار سے چار گنا زیادہ ہے۔ تحقیق سے یہ بھی پتہ چلتا ہے کہ ہلاک ہونے والوں میں سے اب بہت کم یا کوئی تربیت حاصل کرنے والے بڑی عمر کے جنگجو ہیں۔ جیلوں سے بھی خاصی تعداد میں بھرتی کیے گئے ہیں۔ پیش ہیں اس خصوصی رپورٹ کے ساتھ ہماری نامہ نگار اولگا ایوشینا۔ اوکسینکو، میکسم اناتولیوچ۔ یہ ہیں...\n","output_type":"stream"}]},{"cell_type":"code","source":"#This is for 11lab dependencies\n!pip uninstall -y pydantic\n!pip uninstall -y typing-extensions\n!pip install pydantic==2.4.2\n!pip install typing-extensions==4.8.0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install  elevenlabs\nfrom elevenlabs.client import ElevenLabs\nfrom elevenlabs import play, save\n\nclient = ElevenLabs(\n  api_key=\"f5d57646405fc1a301571500835ccd3f\", # Defaults to ELEVEN_API_KEY\n)\n\nvoice = client.clone(\n    name=\"Alex\",\n    description=\"An old American male voice with a slight hoarseness in his throat. Perfect for news\", # Optional\n    files=[audio_file],\n)\nmodel='eleven_multilingual_v2'\naudio = client.generate(text=translated_text,voice=voice,model=model)\nsave(audio,'/kaggle/working/clone_audio3.wav')\nplay(audio)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T08:10:23.838641Z","iopub.execute_input":"2024-05-17T08:10:23.838986Z","iopub.status.idle":"2024-05-17T08:10:24.397463Z","shell.execute_reply.started":"2024-05-17T08:10:23.838961Z","shell.execute_reply":"2024-05-17T08:10:24.396074Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":12,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mApiError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[12], line 9\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01melevenlabs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m play, save\n\u001b[1;32m      5\u001b[0m client \u001b[38;5;241m=\u001b[39m ElevenLabs(\n\u001b[1;32m      6\u001b[0m   api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf5d57646405fc1a301571500835ccd3f\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m# Defaults to ELEVEN_API_KEY\u001b[39;00m\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 9\u001b[0m voice \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAlex\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAn old American male voice with a slight hoarseness in his throat. Perfect for news\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Optional\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43maudio_file\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meleven_multilingual_v2\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     15\u001b[0m audio \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mgenerate(text\u001b[38;5;241m=\u001b[39mtranslated_text,voice\u001b[38;5;241m=\u001b[39mvoice,model\u001b[38;5;241m=\u001b[39mmodel)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/elevenlabs/client.py:107\u001b[0m, in \u001b[0;36mElevenLabs.clone\u001b[0;34m(self, name, files, description, labels, request_options)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclone\u001b[39m(\n\u001b[1;32m     84\u001b[0m   \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     85\u001b[0m   name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     89\u001b[0m   request_options: typing\u001b[38;5;241m.\u001b[39mOptional[RequestOptions] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     90\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Voice:\n\u001b[1;32m     91\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m      This is a manually maintained helper function that clones a voice from a set of audio files.\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m      **NOTE**: This function is a helper function and is simply making \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m          - request_options: typing.Optional[RequestOptions]. Request-specific configuration.\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m     add_voice_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvoices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m      \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvoices\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    114\u001b[0m       add_voice_response\u001b[38;5;241m.\u001b[39mvoice_id,\n\u001b[1;32m    115\u001b[0m       request_options\u001b[38;5;241m=\u001b[39mrequest_options\n\u001b[1;32m    116\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/elevenlabs/voices/client.py:500\u001b[0m, in \u001b[0;36mVoicesClient.add\u001b[0;34m(self, name, files, description, labels, request_options)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError:\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ApiError(status_code\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mstatus_code, body\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mtext)\n\u001b[0;32m--> 500\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ApiError(status_code\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mstatus_code, body\u001b[38;5;241m=\u001b[39m_response_json)\n","\u001b[0;31mApiError\u001b[0m: status_code: 403, body: {'detail': {'status': 'voice_add_edit_limit_reached', 'message': 'You have reached your monthly limit of voice add/edit operations (65). Please consider upgrading your subscription to increase your limit.'}}"],"ename":"ApiError","evalue":"status_code: 403, body: {'detail': {'status': 'voice_add_edit_limit_reached', 'message': 'You have reached your monthly limit of voice add/edit operations (65). Please consider upgrading your subscription to increase your limit.'}}","output_type":"error"}]},{"cell_type":"code","source":"#** wav2lip code starts here\n# !rm -rf /content/sample_data\n# !mkdir /content/sample_data\n# !git clone https://github.com/justinjohn0306/Wav2Lip\n# %cd Wav2Lip\n# #download the pretrained model\n# !wget 'https://github.com/justinjohn0306/Wav2Lip/releases/download/models/wav2lip.pth' -O 'checkpoints/wav2lip.pth'\n# !wget 'https://github.com/justinjohn0306/Wav2Lip/releases/download/models/wav2lip_gan.pth' -O 'checkpoints/wav2lip_gan.pth'\n# !wget 'https://github.com/justinjohn0306/Wav2Lip/releases/download/models/resnet50.pth' -O 'checkpoints/resnet50.pth'\n# !wget 'https://github.com/justinjohn0306/Wav2Lip/releases/download/models/mobilenet.pth' -O 'checkpoints/mobilenet.pth'\n# a = !pip install https://raw.githubusercontent.com/AwaleSajil/ghc/master/ghc-1.0-py3-none-any.whl\n# !pip install git+https://github.com/elliottzheng/batch-face.git@master\n# !pip install ffmpeg-python mediapipe==0.8.11\n\n\ndef free_cuda_memory():\n    torch.cuda.empty_cache()\n    # Optionally, you can also clear cache by deleting tensors\n    # and forcing garbage collection\n    import gc\n    gc.collect()\n    torch.cuda.empty_cache()\n\n# Example usage\nif __name__ == \"__main__\":\n    # Simulate GPU usage\n    a = torch.randn(10000, 10000, device='cuda')\n    \n    # Free up the GPU memory\n    del a\n    free_cuda_memory()\n\n    print(\"GPU memory freed.\")","metadata":{"execution":{"iopub.status.busy":"2024-05-17T08:02:39.026382Z","iopub.execute_input":"2024-05-17T08:02:39.027375Z","iopub.status.idle":"2024-05-17T08:02:39.212378Z","shell.execute_reply.started":"2024-05-17T08:02:39.027337Z","shell.execute_reply":"2024-05-17T08:02:39.211498Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"GPU memory freed.\n","output_type":"stream"}]},{"cell_type":"code","source":"#@title STEP4: Start Crunching and Preview Output\nvariable_name = False\n\n# %cd /content/Wav2Lip\n\n# Set up paths and variables for the output file\noutput_file_path = '/Wav2Lip/results/result_voice.mp4'\n\n# Delete existing output file before processing, if any\n# if os.path.exists(output_file_path):\n#     os.remove(output_file_path)\n\npad_top = 0\npad_bottom = 10\npad_left = 0\npad_right = 0\nrescaleFactor = 1\nnosmooth = True\nvariable_name = False\nuse_hd_model = False\ncheckpoint_path = 'checkpoints/wav2lip.pth' if not use_hd_model else 'checkpoints/wav2lip_gan.pth'\n\n\nif nosmooth == False:\n  !python inference.py --checkpoint_path $checkpoint_path --face \"/kaggle/input/ukrain-war/ukrain.mp4\" --audio \"/kaggle/input/clonned/clone_audio3 (1).wav\" --pads $pad_top $pad_bottom $pad_left $pad_right --resize_factor $rescaleFactor\nelse:\n  !python inference.py --checkpoint_path $checkpoint_path --face \"/kaggle/input/ukrain-war/ukrain.mp4\" --audio \"/kaggle/input/clonned/clone_audio3 (1).wav\" --pads $pad_top $pad_bottom $pad_left $pad_right --resize_factor $rescaleFactor --nosmooth\n\n#Preview output video\nif os.path.exists(output_file_path):\n    clear_output()\n    print(\"Final Video Preview\")\n    print(\"Download this video from\", output_file_path)\n    # showVideo(output_file_path)\nelse:\n    print(\"Processing failed. Output video not found.\")","metadata":{"execution":{"iopub.status.busy":"2024-05-17T08:12:16.968351Z","iopub.execute_input":"2024-05-17T08:12:16.968870Z","iopub.status.idle":"2024-05-17T08:12:36.266770Z","shell.execute_reply.started":"2024-05-17T08:12:16.968832Z","shell.execute_reply":"2024-05-17T08:12:36.265629Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Using cuda for inference.\nLoad checkpoint from: checkpoints/wav2lip.pth\nModels loaded\nReading video frames...\nNumber of frames available for inference: 724\n(80, 2830)\nLength of mel chunks: 881\n  0%|                                                     | 0/7 [00:04<?, ?it/s]\nTraceback (most recent call last):\n  File \"/kaggle/working/Wav2Lip/inference.py\", line 323, in <module>\n    main()\n  File \"/kaggle/working/Wav2Lip/inference.py\", line 254, in main\n    for i, (img_batch, mel_batch, frames, coords) in enumerate(tqdm(gen,\n  File \"/opt/conda/lib/python3.10/site-packages/tqdm/std.py\", line 1182, in __iter__\n    for obj in iterable:\n  File \"/kaggle/working/Wav2Lip/inference.py\", line 104, in datagen\n    face_det_results = face_detect(frames) # BGR2RGB for CNN face detection\n  File \"/kaggle/working/Wav2Lip/inference.py\", line 78, in face_detect\n    for image, rect in zip(images, face_rect(images)):\n  File \"/kaggle/working/Wav2Lip/inference.py\", line 312, in face_rect\n    all_faces = detector(batch)  # return faces list of all images\n  File \"/opt/conda/lib/python3.10/site-packages/batch_face/face_detection/detector.py\", line 82, in __call__\n    return self.detect(images, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/batch_face/face_detection/detector.py\", line 67, in detect\n    return batch_detect(self.model, np.array(images), **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n    return func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/batch_face/face_detection/alignment.py\", line 588, in batch_detect\n    loc, conf, landms = net(img)  # forward pass\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/batch_face/face_detection/alignment.py\", line 261, in forward\n    out = self.body(inputs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py\", line 69, in forward\n    x = module(x)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 215, in forward\n    input = module(input)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 215, in forward\n    input = module(input)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py\", line 171, in forward\n    return F.batch_norm(\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py\", line 2478, in batch_norm\n    return torch.batch_norm(\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.56 GiB. GPU 0 has a total capacty of 14.75 GiB of which 905.06 MiB is free. Process 2951 has 9.65 GiB memory in use. Process 7009 has 4.21 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 43.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n\u001b[0mProcessing failed. Output video not found.\n","output_type":"stream"}]}]}